{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.prepro import *\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_process(file_name,trainHRPath):\n",
    "    im = Image.open(trainHRPath+\"/\"+file_name)\n",
    "    im.save(trainHRPath+\"/\"+str(file_name[0:-3])+\"png\")\n",
    "    return True\n",
    "\n",
    "def downsample_fn(x,savePath):\n",
    "    # We obtained the LR images by downsampling the HR images using bicubic kernel with downsampling factor r = 4.\n",
    "    im = imresize(x[0], size=[int(np.floor(x[0].shape[0]/4)),int(np.floor(x[0].shape[1]/4))], interp='bicubic', mode=None)\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(savePath+\"/\"+str(x[1][0:-3])+\"png\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHRPath = \"stage/train/HR\"\n",
    "testHRPath = \"stage/test/HR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHR = sorted(tl.files.load_file_list(path=trainHRPath, regx='.*.jpg', printable=False))\n",
    "testHR = sorted(tl.files.load_file_list(path=testHRPath, regx='.*.jpg', printable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] read 32 from stage/train/HR\n",
      "[TL] read 64 from stage/train/HR\n",
      "[TL] read 96 from stage/train/HR\n",
      "[TL] read 128 from stage/train/HR\n",
      "[TL] read 160 from stage/train/HR\n",
      "[TL] read 192 from stage/train/HR\n",
      "[TL] read 224 from stage/train/HR\n",
      "[TL] read 256 from stage/train/HR\n",
      "[TL] read 288 from stage/train/HR\n",
      "[TL] read 300 from stage/train/HR\n"
     ]
    }
   ],
   "source": [
    "train_hr_imgs = tl.vis.read_images(trainHR, path=trainHRPath, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippedPair = list(zip(train_hr_imgs,trainHR))\n",
    "_ = tl.prepro.threading_data(zippedPair, fn=downsample_fn,savePath=\"stage/train/LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_hr_imgs,zippedPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] read 32 from stage/test/HR\n",
      "[TL] read 64 from stage/test/HR\n",
      "[TL] read 96 from stage/test/HR\n",
      "[TL] read 128 from stage/test/HR\n",
      "[TL] read 160 from stage/test/HR\n",
      "[TL] read 192 from stage/test/HR\n",
      "[TL] read 200 from stage/test/HR\n"
     ]
    }
   ],
   "source": [
    "test_hr_imgs = tl.vis.read_images(testHR, path=testHRPath, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [*] creates stage/test/LR ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.files.exists_or_mkdir(\"stage/test/LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippedPair = list(zip(test_hr_imgs,testHR))\n",
    "_ = tl.prepro.threading_data(zippedPair, fn=downsample_fn,savePath=\"stage/test/LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_hr_imgs,zippedPair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.prepro.threading_data(trainHR, fn=convert_process,trainHRPath=trainHRPath)\n",
    "_ = tl.prepro.threading_data(testHR, fn=convert_process,trainHRPath=testHRPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fl in glob.glob(trainHRPath+\"/*.jpg\"):\n",
    "    os.remove(fl)\n",
    "for fl in glob.glob(testHRPath+\"/*.jpg\"):\n",
    "    os.remove(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
